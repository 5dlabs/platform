name: Unified Platform CI/CD

# This workflow includes auto-formatting capabilities:
# - If Rust code formatting fails, it will automatically run `cargo fmt --all`
# - The formatted code will be committed and pushed back to the branch
# - The CI will then re-run to verify the formatting is correct
# - This only happens on push events, not on pull requests

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_BASE: ${{ github.repository }}

jobs:
  # Change detection job
  changes:
    runs-on: ubuntu-latest
    outputs:
      claude-code: ${{ steps.filter.outputs.claude-code }}
      orchestrator: ${{ steps.filter.outputs.orchestrator }}
      taskrun: ${{ steps.filter.outputs.taskrun }}
      infra: ${{ steps.filter.outputs.infra }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            claude-code:
              - 'infra/images/claude-code/**'
            orchestrator:
              - 'orchestrator/**'
              - '!orchestrator/**/*.md'
            taskrun:
              - 'orchestrator/orchestrator-core/src/controllers/taskrun.rs'
              - 'orchestrator/orchestrator-core/src/crds/**'
              - 'infra/test-resources/crds/**'
            infra:
              - 'infra/**'
              - '.github/workflows/**'

  # Version determination
  version:
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
      is-release: ${{ steps.version.outputs.is-release }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine version
        id: version
        run: |
          if [[ "${{ github.ref }}" == refs/tags/v* ]]; then
            VERSION="${{ github.ref_name }}"
            echo "version=${VERSION}" >> $GITHUB_OUTPUT
            echo "is-release=true" >> $GITHUB_OUTPUT
          else
            # Use commit SHA for non-release builds
            VERSION="main-$(git rev-parse --short HEAD)"
            echo "version=${VERSION}" >> $GITHUB_OUTPUT
            echo "is-release=false" >> $GITHUB_OUTPUT
          fi

  # Parallel linting and testing
  lint-rust:
    needs: changes
    if: needs.changes.outputs.orchestrator == 'true' || needs.changes.outputs.taskrun == 'true' || github.event_name == 'push'
    runs-on: ubuntu-22.04
    outputs:
      format-needed: ${{ steps.format-check.outputs.format-needed }}
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy
      - uses: Swatinem/rust-cache@v2
        with:
          workspaces: orchestrator -> target
          # Share cache between jobs
          shared-key: "rust-cache-agent-platform"

      - name: Auto-format code
        id: format-check
        working-directory: ./orchestrator
        run: |
          echo "üîß Running cargo fmt to ensure consistent formatting..."
          if ! cargo fmt --all -- --check; then
            echo "üìù Formatting issues detected - applying auto-format..."
            cargo fmt --all
            echo "format-needed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Code formatting automatically fixed"
          else
            echo "format-needed=false" >> $GITHUB_OUTPUT
            echo "‚úÖ Code formatting is already correct"
          fi

      - name: Run Clippy
        working-directory: ./orchestrator
        run: cargo clippy --all-targets --all-features -- -D warnings

  # Commit formatting changes (runs on any event when formatting was needed)
  commit-format-changes:
    needs: [changes, lint-rust]
    if: always() && needs.lint-rust.outputs.format-needed == 'true'
    runs-on: ubuntu-22.04
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          # Use a personal access token to trigger subsequent workflows
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt

      - name: Auto-format Rust code
        working-directory: ./orchestrator
        run: |
          echo "üîß Auto-formatting Rust code..."
          cargo fmt --all

      - name: Check for changes
        id: changes
        run: |
          if git diff --quiet; then
            echo "No changes after formatting"
            echo "has-changes=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected after formatting"
            echo "has-changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.changes.outputs.has-changes == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit -m "üîß Auto-format Rust code

          This commit was automatically generated by the CI/CD pipeline
          to fix formatting issues detected by cargo fmt.

          Changes made:
          - Applied cargo fmt --all to fix formatting

          [skip ci]"
          git push

      - name: Comment on commit
        if: steps.changes.outputs.has-changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const sha = context.sha;

            await github.rest.repos.createCommitComment({
              owner,
              repo,
              commit_sha: sha,
              body: `üîß **Auto-formatting applied**

              Code formatting was automatically fixed and committed.

              üí° **Tip**: Run \`cargo fmt --all\` locally to avoid this in the future.`
            });

  # Re-run lint after auto-format (only if auto-format ran)
  lint-rust-retry:
    needs: [changes, commit-format-changes]
    if: always() && needs.commit-format-changes.result == 'success'
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4
        with:
          # Fetch the latest commit (including auto-format changes)
          ref: ${{ github.ref }}

      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - uses: Swatinem/rust-cache@v2
        with:
          workspaces: orchestrator -> target
          shared-key: "rust-cache-agent-platform"

      - name: Verify formatting is now correct
        working-directory: ./orchestrator
        run: |
          echo "üîç Verifying formatting after auto-format..."
          cargo fmt --all -- --check

      - name: Run Clippy
        working-directory: ./orchestrator
        run: cargo clippy --all-targets --all-features -- -D warnings

  test-rust:
    needs: changes
    if: needs.changes.outputs.orchestrator == 'true' || needs.changes.outputs.taskrun == 'true' || github.event_name == 'push'
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2
        with:
          workspaces: orchestrator -> target
          # Share cache between jobs
          shared-key: "rust-cache-agent-platform"

      - name: Run tests
        working-directory: ./orchestrator
        run: cargo test --all-features --all-targets

  # Integration tests
  integration-tests:
    needs: [lint-rust, test-rust, lint-rust-retry]
    if: always() && !cancelled() && (needs.changes.outputs.orchestrator == 'true' || needs.changes.outputs.taskrun == 'true' || needs.changes.outputs.infra == 'true' || github.event_name == 'push') && (needs.lint-rust.result == 'success' || needs.lint-rust-retry.result == 'success')
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4

      # Cache kubectl binary
      - name: Cache kubectl
        uses: actions/cache@v4
        with:
          path: /usr/local/bin/kubectl
          key: kubectl-agent-platform-${{ runner.os }}-1.30.0

      - name: Create Kind cluster
        uses: helm/kind-action@v1.8.0
        with:
          cluster_name: platform-test
          config: .github/kind-config.yaml
          kubectl_version: v1.30.0
          # Wait longer for cluster to be ready
          wait: 120s
          verbosity: 1

      - name: Test Helm Chart Structure
        run: |
          echo "üéØ Testing orchestrator Helm chart..."

          # Install Helm
          curl -fsSL https://get.helm.sh/helm-v3.14.0-linux-amd64.tar.gz | tar xz
          sudo mv linux-amd64/helm /usr/local/bin/
          helm version

          # Lint the Helm chart
          helm lint ./infra/charts/orchestrator

          # Test template generation with different values
          echo "üìã Testing default values..."
          helm template orchestrator ./infra/charts/orchestrator > /tmp/default.yaml
          kubectl --dry-run=client apply -f /tmp/default.yaml

          echo "üìã Testing with secrets..."
          helm template orchestrator ./infra/charts/orchestrator \
            --set secrets.anthropicApiKey="test-key" \
            --set secrets.githubToken="test-token" > /tmp/with-secrets.yaml
          kubectl --dry-run=client apply -f /tmp/with-secrets.yaml

          echo "üìã Testing with custom image..."
          helm template orchestrator ./infra/charts/orchestrator \
            --set image.repository="custom/repo" \
            --set image.tag="v1.2.3" > /tmp/custom-image.yaml
          kubectl --dry-run=client apply -f /tmp/custom-image.yaml

          echo "‚úÖ Helm chart validation passed!"

      - name: Deploy test resources
        run: |
          # Create test namespace
          kubectl create namespace test-platform

          # Install CRD definitions first
          echo "üèóÔ∏è  Installing CRD definitions..."
          kubectl apply -f infra/charts/orchestrator/templates/coderun-crd.yaml
          kubectl apply -f infra/charts/orchestrator/templates/docsrun-crd.yaml

          # Apply test CodeRun and DocsRun instances
          echo "üß™ Applying test CRD instances..."
          kubectl apply -f infra/test-resources/crds/test-coderun.yaml -n test-platform || true
          kubectl apply -f infra/test-resources/crds/test-docsrun.yaml -n test-platform || true

      - name: Verify CRD deployment
        run: |
          kubectl get crd coderuns.orchestrator.platform
          kubectl get crd docsruns.orchestrator.platform
          kubectl get coderuns,docsruns -A

  # Security scanning (non-blocking, self-hosted)
  security-scan:
    needs: changes
    if: github.event_name == 'push'  # Only on main branch
    runs-on: ubuntu-latest
    continue-on-error: true  # Non-blocking
    steps:
      - uses: actions/checkout@v4

      # Cache Trivy DB
      - name: Cache Trivy database
        uses: actions/cache@v4
        with:
          path: ~/.cache/trivy
          key: trivy-db-${{ runner.os }}-${{ github.run_id }}
          restore-keys: |
            trivy-db-${{ runner.os }}-

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          cache-dir: ~/.cache/trivy

      - name: Upload Trivy scan results
        uses: actions/upload-artifact@v4
        with:
          name: trivy-results
          path: trivy-results.sarif

      # Cache cargo-audit binary
      - name: Cache cargo-audit
        uses: actions/cache@v4
        id: cargo-audit-cache
        with:
          path: ~/.cargo/bin/cargo-audit
          key: cargo-audit-${{ runner.os }}-0.21.2

      - name: Install cargo-audit
        if: steps.cargo-audit-cache.outputs.cache-hit != 'true'
        run: cargo install cargo-audit --version 0.21.2

      - name: Rust security audit
        working-directory: ./orchestrator
        run: cargo audit || true  # Non-blocking

  # Test coverage reporting (non-blocking)
  test-coverage:
    needs: changes
    if: needs.changes.outputs.orchestrator == 'true' || needs.changes.outputs.taskrun == 'true' || github.event_name == 'push'
    runs-on: ubuntu-22.04
    continue-on-error: true  # Non-blocking
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: llvm-tools-preview
      - uses: Swatinem/rust-cache@v2
        with:
          workspaces: orchestrator -> target
          # Share cache between jobs
          shared-key: "rust-cache-agent-platform"

      # Install cargo-llvm-cov for coverage
      - name: Cache cargo-llvm-cov
        uses: actions/cache@v4
        id: cargo-llvm-cov-cache
        with:
          path: ~/.cargo/bin/cargo-llvm-cov
          key: cargo-llvm-cov-${{ runner.os }}-0.6.8

      - name: Install cargo-llvm-cov
        if: steps.cargo-llvm-cov-cache.outputs.cache-hit != 'true'
        run: cargo install cargo-llvm-cov --version 0.6.8

      - name: Generate test coverage
        working-directory: ./orchestrator
        run: |
          echo "üìä Generating test coverage report..."
          cargo llvm-cov --all-features --workspace --lcov --output-path lcov.info || true
          cargo llvm-cov --all-features --workspace --html --output-dir coverage-html || true

          # Generate summary
          echo "## Test Coverage Summary" > coverage-summary.md
          echo "" >> coverage-summary.md
          if [ -f "lcov.info" ]; then
            # Extract coverage percentage from lcov file
            COVERAGE=$(grep -E "^LF:|^LH:" lcov.info | awk -F: '{if($1=="LF") lf+=$2; if($1=="LH") lh+=$2} END {if(lf>0) printf "%.1f", (lh/lf)*100; else print "0.0"}')
            echo "üìä **Overall Coverage**: ${COVERAGE}%" >> coverage-summary.md
            echo "Coverage: ${COVERAGE}%"
          else
            echo "‚ö†Ô∏è **Coverage**: Could not generate coverage report" >> coverage-summary.md
            echo "Coverage report generation failed"
          fi

          echo "" >> coverage-summary.md
          echo "üìÅ Detailed HTML report available in artifacts" >> coverage-summary.md

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            orchestrator/lcov.info
            orchestrator/coverage-html/
            orchestrator/coverage-summary.md

      - name: Display coverage summary
        working-directory: ./orchestrator
        run: |
          if [ -f "coverage-summary.md" ]; then
            echo "üìä Test Coverage Results:"
            cat coverage-summary.md
          else
            echo "‚ö†Ô∏è Coverage summary not available"
          fi

  # Build images
  build-claude-code:
    needs: [version, lint-rust, test-rust, integration-tests, lint-rust-retry]
    if: always() && !cancelled() && (needs.changes.outputs.claude-code == 'true' || github.event_name == 'push')
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4

      - name: Get Claude Code CLI version
        id: claude-version
        run: |
          CLAUDE_VERSION=$(npm view @anthropic-ai/claude-code version)
          echo "CLAUDE_VERSION=$CLAUDE_VERSION" >> $GITHUB_OUTPUT
          echo "üì¶ Latest Claude Code CLI version on npm: $CLAUDE_VERSION"

      - name: Log in to Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Check if Claude Code image exists
        id: claude-exists
        run: |
          echo "üîç Checking if we have built Claude Code version ${{ steps.claude-version.outputs.CLAUDE_VERSION }}"
          echo "Looking for: ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ steps.claude-version.outputs.CLAUDE_VERSION }}"
          if docker manifest inspect ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ steps.claude-version.outputs.CLAUDE_VERSION }} > /dev/null 2>&1; then
            echo "‚úÖ We already have this version built, skipping build"
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "üèóÔ∏è We haven't built this version yet, will build"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Docker Buildx
        if: steps.claude-exists.outputs.exists == 'false'
        uses: docker/setup-buildx-action@v3

      - name: Build and push Claude Code image
        if: steps.claude-exists.outputs.exists == 'false'
        uses: docker/build-push-action@v5
        with:
          context: ./infra/images/claude-code
          file: ./infra/images/claude-code/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: ${{ github.event_name != 'pull_request' }}
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:latest
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ needs.version.outputs.version }}
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ steps.claude-version.outputs.CLAUDE_VERSION }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1
            CLAUDE_CODE_VERSION=${{ steps.claude-version.outputs.CLAUDE_VERSION }}

      - name: Tag existing image with platform version
        if: steps.claude-exists.outputs.exists == 'true' && github.event_name != 'pull_request'
        run: |
          echo "üè∑Ô∏è Tagging existing image with platform version"
          docker buildx imagetools create \
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ steps.claude-version.outputs.CLAUDE_VERSION }} \
            --tag ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ needs.version.outputs.version }}

  build-orchestrator:
    needs: [version, lint-rust, test-rust, integration-tests, lint-rust-retry]
    if: always() && !cancelled() && (needs.changes.outputs.orchestrator == 'true' || github.event_name == 'push')
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2
        with:
          workspaces: orchestrator -> target
          # Share cache with other jobs and cache release artifacts
          shared-key: "rust-cache"
          cache-targets: true

      - name: Build release binary
        working-directory: ./orchestrator
        run: |
          echo "üî® Building orchestrator-core for container..."
          cargo build --release --package core
          cp target/release/orchestrator-core orchestrator

          echo "üî® Building orchestrator-mcp for release..."
          cargo build --release --package mcp

          echo "üî® Building orchestrator-cli for release..."
          cargo build --release --package cli

      - name: Prepare release artifacts
        working-directory: ./orchestrator
        run: |
          echo "üì¶ Preparing release artifacts..."
          mkdir -p release-artifacts

          # Copy binaries to release artifacts
          cp target/release/orchestrator-mcp release-artifacts/
          cp target/release/orchestrator-cli release-artifacts/

          # Create platform-specific archives
          echo "üóúÔ∏è Creating release archives..."

          # Linux x64 archive
          tar -czf release-artifacts/orchestrator-tools-linux-x64.tar.gz \
            -C target/release orchestrator-mcp orchestrator-cli

          # Create checksums
          cd release-artifacts
          sha256sum orchestrator-mcp orchestrator-cli orchestrator-tools-linux-x64.tar.gz > checksums.txt

          echo "‚úÖ Release artifacts prepared:"
          ls -la

      - name: Upload release artifacts
        uses: actions/upload-artifact@v4
        with:
          name: orchestrator-release-artifacts
          path: orchestrator/release-artifacts/
          retention-days: 30

  build-gemini-cli:
    needs: [version, lint-rust, test-rust, integration-tests, lint-rust-retry]
    if: always() && !cancelled() && github.event_name == 'push'  # Always build Gemini CLI on push
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout platform repository
        uses: actions/checkout@v4

      - name: Checkout Gemini CLI repository
        uses: actions/checkout@v4
        with:
          repository: google-gemini/gemini-cli
          ref: main
          path: gemini-cli

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: gemini-cli/package-lock.json

      - name: Install dependencies and build packages
        working-directory: ./gemini-cli
        run: |
          npm ci
          npm run build:packages
          npm pack -w @google/gemini-cli --pack-destination ./packages/cli/dist
          npm pack -w @google/gemini-cli-core --pack-destination ./packages/core/dist

      - name: Get CLI version
        id: cli-version
        working-directory: ./gemini-cli
        run: |
          CLI_VERSION=$(node -p "require('./packages/cli/package.json').version")
          echo "CLI_VERSION=$CLI_VERSION" >> $GITHUB_OUTPUT
          echo "üì¶ Gemini CLI version from source: $CLI_VERSION"

      - name: Log in to Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Check if Gemini CLI image exists
        id: gemini-exists
        run: |
          echo "üîç Checking if we have built Gemini CLI version ${{ steps.cli-version.outputs.CLI_VERSION }}"
          echo "Looking for: ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ steps.cli-version.outputs.CLI_VERSION }}"
          if docker manifest inspect ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ steps.cli-version.outputs.CLI_VERSION }} > /dev/null 2>&1; then
            echo "‚úÖ We already have this version built, skipping build"
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "üèóÔ∏è We haven't built this version yet, will build"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Docker Buildx
        if: steps.gemini-exists.outputs.exists == 'false'
        uses: docker/setup-buildx-action@v3

      - name: Build and push Gemini CLI image
        if: steps.gemini-exists.outputs.exists == 'false'
        uses: docker/build-push-action@v5
        with:
          context: ./gemini-cli
          file: ./gemini-cli/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: ${{ github.event_name != 'pull_request' }}
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:latest
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ needs.version.outputs.version }}
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ steps.cli-version.outputs.CLI_VERSION }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          # Add registry cache for better layer reuse
          build-args: |
            BUILDKIT_INLINE_CACHE=1
            CLI_VERSION_ARG=${{ steps.cli-version.outputs.CLI_VERSION }}

      - name: Tag existing image with platform version
        if: steps.gemini-exists.outputs.exists == 'true' && github.event_name != 'pull_request'
        run: |
          echo "üè∑Ô∏è Tagging existing image with platform version"
          docker buildx imagetools create \
            ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ steps.cli-version.outputs.CLI_VERSION }} \
            --tag ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ needs.version.outputs.version }}

  # Deploy to single environment (only on main branch)
  deploy:
    needs: [version, build-claude-code, build-orchestrator, build-gemini-cli]
    if: (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')) && github.event_name == 'push'
    runs-on: [self-hosted]
    steps:
      - uses: actions/checkout@v4

      - name: Setup tools
        run: |
          # Create local bin directory
          mkdir -p $HOME/bin

          # Copy tools from shared location if they exist
          if [ -f /shared/kubectl ]; then
            cp /shared/kubectl $HOME/bin/
            chmod +x $HOME/bin/kubectl
          fi

          if [ -f /shared/helm ]; then
            cp /shared/helm $HOME/bin/
            chmod +x $HOME/bin/helm
          fi

          # Add to PATH for this job
          echo "$HOME/bin" >> $GITHUB_PATH

      - name: Verify tools
        run: |
          echo "Checking tools..."
          kubectl version --client || echo "kubectl failed"
          helm version || echo "helm failed"

      - name: Verify Kubernetes access
        run: |
          echo "üîç Verifying Kubernetes access..."
          kubectl cluster-info

      - name: Deploy Orchestrator with Helm
        run: |
          echo "üöÄ Deploying platform version ${{ needs.version.outputs.version }}"

          # Deploy the orchestrator (TaskRun controller manages Claude Code and Gemini CLI agents)
          helm upgrade --install orchestrator ./infra/charts/orchestrator \
            --namespace orchestrator \
            --create-namespace \
            --values infra/charts/orchestrator/values.yaml \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/orchestrator \
            --set image.tag=${{ needs.version.outputs.version }} \
            --set secrets.anthropicApiKey="${{ secrets.ANTHROPIC_API_KEY }}" \
            --set secrets.githubToken="${{ secrets.GH_TOKEN_FOR_AGENTS }}" \
            --timeout 10m \
            --wait \
            --atomic

          echo "üìã Available agent images for TaskRun resources:"
          echo "- Claude Code: ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ needs.version.outputs.version }}"
          echo "- Gemini CLI: ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ needs.version.outputs.version }}"

      - name: Verify deployment
        run: |
          echo "üîç Verifying deployment..."
          kubectl get pods -n orchestrator
          kubectl get services -n orchestrator
          kubectl get coderuns,docsruns -A || echo "No CodeRuns/DocsRuns found (expected for fresh deployment)"

          # Wait for orchestrator to be ready
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=orchestrator -n orchestrator --timeout=300s

          echo "‚úÖ Deployment verification complete!"

      - name: Deployment notification
        run: |
          echo "üéâ Successfully deployed platform version ${{ needs.version.outputs.version }}"
          echo ""
          echo "Images deployed:"
          echo "- ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ needs.version.outputs.version }}"
          echo "- ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/orchestrator:${{ needs.version.outputs.version }}"
          echo "- ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ needs.version.outputs.version }}"
          echo "  (Gemini CLI also tagged with its official version from Google)"
          echo ""
          echo "CLI Tools & MCP Server built:"
          echo "- orchestrator-mcp (MCP server for AI development environments)"
          echo "- orchestrator-cli (Command-line interface)"
          echo "- Available as GitHub release artifacts for download"
          echo ""
          echo "Cluster status:"
          kubectl get pods -n orchestrator -o wide

  # Create release (only for tags)
  release:
    needs: [version, deploy, build-orchestrator]
    if: needs.version.outputs.is-release == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Download release artifacts
        uses: actions/download-artifact@v4
        with:
          name: orchestrator-release-artifacts
          path: ./release-artifacts

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ needs.version.outputs.version }}
          name: Release ${{ needs.version.outputs.version }}
          body: |
            ## Container Images

            This release includes the following container images:
            - `${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/claude-code:${{ needs.version.outputs.version }}`
            - `${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/orchestrator:${{ needs.version.outputs.version }}`
            - `${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/gemini-cli:${{ needs.version.outputs.version }}`

            ## CLI Tools & MCP Server

            This release includes standalone CLI tools and MCP server:
            - **orchestrator-mcp**: MCP server for AI development environments (Cursor, etc.)
            - **orchestrator-cli**: Command-line interface for direct orchestrator interaction

            ### Download Options:
            - **Individual binaries**: Download `orchestrator-mcp` or `orchestrator-cli` directly
            - **Archive**: Download `orchestrator-tools-linux-x64.tar.gz` for both tools
            - **Checksums**: Verify downloads using `checksums.txt`

            ### Installation:
            ```bash
            # Download and extract tools
            wget https://github.com/5dlabs/platform/releases/download/${{ needs.version.outputs.version }}/orchestrator-tools-linux-x64.tar.gz
            tar -xzf orchestrator-tools-linux-x64.tar.gz

            # Make executable and install
            chmod +x orchestrator-mcp orchestrator-cli
            sudo mv orchestrator-mcp orchestrator-cli /usr/local/bin/
            ```

            ## Deployment

            Update your Helm values or Kubernetes manifests to use the new image tags.
          files: |
            release-artifacts/*
          draft: false

# OpenTelemetry Collector Helm Values for Claude Code Telemetry
mode: deployment
replicaCount: 1

# Image configuration
image:
  repository: otel/opentelemetry-collector-contrib
  pullPolicy: IfNotPresent
  tag: "0.105.0"

# Resource allocation - adjusted for development environment
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

# Service configuration
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    protocol: TCP
  prometheus:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    protocol: TCP

# OpenTelemetry Collector configuration
config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
          max_recv_msg_size_mib: 64
        http:
          endpoint: 0.0.0.0:4318
          cors:
            allowed_origins:
              - "*"

  processors:
    batch:
      timeout: 10s
      send_batch_size: 1024
      send_batch_max_size: 2048
    
    memory_limiter:
      check_interval: 1s
      limit_mib: 1500
      spike_limit_mib: 512
    
    resource:
      attributes:
        - key: cluster.name
          value: telemetry-dev
          action: insert
        - key: deployment.environment
          value: development
          action: insert
    
    # Transform metric names from dots to underscores for Prometheus compatibility
    # NOTE: Claude Code emits metrics WITHOUT the claude_code prefix!
    transform/metrics:
      metric_statements:
        - context: datapoint
          statements:
            # Transform actual metric names (no prefix) to Prometheus format with prefix
            - set(metric.name, "claude_code_lines_of_code_count") where metric.name == "lines_of_code.count"
            - set(metric.name, "claude_code_cost_usage") where metric.name == "cost.usage"
            - set(metric.name, "claude_code_token_usage") where metric.name == "token.usage"
            - set(metric.name, "claude_code_session_count") where metric.name == "session.count"
            - set(metric.name, "claude_code_commit_count") where metric.name == "commit.count"
            - set(metric.name, "claude_code_pull_request_count") where metric.name == "pull_request.count"
            - set(metric.name, "claude_code_code_edit_tool_decision") where metric.name == "code_edit_tool.decision"

  exporters:
    prometheus:
      endpoint: "0.0.0.0:8889"
      send_timestamps: true
    
    # VictoriaMetrics native OpenTelemetry exporter
    otlphttp/victoriametrics:
      metrics_endpoint: http://victoria-metrics-victoria-metrics-single-server:8428/opentelemetry/v1/metrics
      compression: gzip
      encoding: proto
      tls:
        insecure: true
      timeout: 30s
      retry_on_failure:
        enabled: true
        initial_interval: 5s
        max_interval: 30s
        max_elapsed_time: 300s
    
    # VictoriaLogs exporter using OTLP/HTTP
    otlphttp:
      logs_endpoint: http://victoria-logs-victoria-logs-single-server:9428/insert/opentelemetry/v1/logs
      tls:
        insecure: true
      retry_on_failure:
        enabled: true
        initial_interval: 5s
        max_interval: 30s
        max_elapsed_time: 300s
      headers:
        VL-Stream-Fields: "cluster.name,deployment.environment,service.name,service.namespace"
    
    # Debug exporter for troubleshooting
    debug:
      verbosity: detailed
      sampling_initial: 5
      sampling_thereafter: 200

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133
    pprof:
      endpoint: 0.0.0.0:1777
    zpages:
      endpoint: 0.0.0.0:55679

  service:
    extensions: [health_check, pprof, zpages]
    pipelines:
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, batch, resource, transform/metrics]
        exporters: [otlphttp/victoriametrics, prometheus, debug]
      logs:
        receivers: [otlp]
        processors: [memory_limiter, batch, resource]
        exporters: [otlphttp, debug]
      traces:
        receivers: [otlp]
        processors: [memory_limiter, batch, resource]
        exporters: [debug]
    telemetry:
      metrics:
        level: detailed
        address: 0.0.0.0:8890

# Pod annotations for monitoring
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8890"
  prometheus.io/path: "/metrics"

# Liveness and readiness probes
livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 5

# Ingress configuration for OTLP endpoints
ingress:
  enabled: true
  ingressClassName: nginx
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/grpc-backend: "true"
  hosts:
    - host: otel-grpc.local
      paths:
        - path: /
          pathType: Prefix
          port: 4317
    - host: otel-http.local
      paths:
        - path: /
          pathType: Prefix
          port: 4318